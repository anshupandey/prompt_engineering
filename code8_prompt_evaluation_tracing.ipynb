{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshupandey/prompt_engineering/blob/main/code8_prompt_evaluation_tracing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bbc1156",
      "metadata": {
        "id": "3bbc1156"
      },
      "source": [
        "# Prompt Evaluation and Tracing with MLflow\n",
        "This notebook is designed to help you evaluate and trace prompts using MLflow. It provides a structured way to log prompt evaluations, track their performance, and visualize the results over time.\n",
        "\n",
        "Key Benefits of MLflow Prompt Evaluation\n",
        "* Effective Evaluation: `MLflow's LLM Evaluation API provides a simple and consistent way to evaluate prompts across different models and datasets without writing boilerplate code.\n",
        "* Compare Results: Compare evaluation results with ease in the MLflow UI.\n",
        "* Tracking Results: Track evaluation results in MLflow Experiment to maintain the history of prompt performance and different evaluation settings.\n",
        "* Tracing: Inspect model behavior during inference deeply with traces generated during evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f45256b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f45256b9",
        "outputId": "14f831ab-29c1-409e-e574-9afc828310a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.7/24.7 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m676.2/676.2 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install mlflow openai --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2a97b8a8",
      "metadata": {
        "id": "2a97b8a8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import mlflow\n",
        "from openai import OpenAI\n",
        "os.environ['OPENAI_API_KEY'] = \"sk-proj-xx-xxx-xx-xx-xx\"\n",
        "mlflow.set_tracking_uri(\"http://20.80.248.210:5000/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d4db162",
      "metadata": {
        "id": "2d4db162"
      },
      "source": [
        "### 1. Create a new prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "574133d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "574133d5",
        "outputId": "87248495-5509-4eac-ee82-0d1fd077f49f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-5-2441474764.py:11: FutureWarning: The `mlflow.register_prompt` API is moved to the `mlflow.genai` namespace. Please use `mlflow.genai.register_prompt` instead. The original API will be removed in the future release.\n",
            "  prompt = mlflow.register_prompt(\n",
            "2025/07/18 12:02:53 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for prompt version to finish creation. Prompt name: anshu-summarization-prompt, version 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created prompt 'anshu-summarization-prompt' (version 3)\n"
          ]
        }
      ],
      "source": [
        "import mlflow\n",
        "\n",
        "# Use double curly braces for variables in the template\n",
        "initial_template = \"\"\"\\\n",
        "Summarize content you are provided with in {{ num_sentences }} sentences.\n",
        "\n",
        "Sentences: {{ sentences }}\n",
        "\"\"\"\n",
        "\n",
        "# Register a new prompt\n",
        "prompt = mlflow.register_prompt(\n",
        "    name=\"anshu-summarization-prompt\",\n",
        "    template=initial_template,\n",
        "    # Optional: Provide a commit message to describe the changes\n",
        "    commit_message=\"Initial commit\",\n",
        ")\n",
        "\n",
        "# The prompt object contains information about the registered prompt\n",
        "print(f\"Created prompt '{prompt.name}' (version {prompt.version})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ff816a5",
      "metadata": {
        "id": "5ff816a5"
      },
      "source": [
        "### 2. Prepare Evaluation Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4c1e3206",
      "metadata": {
        "id": "4c1e3206"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "eval_data = pd.DataFrame(\n",
        "    {\n",
        "        \"inputs\": [\n",
        "            \"Artificial intelligence has transformed how businesses operate in the 21st century. Companies are leveraging AI for everything from customer service to supply chain optimization. The technology enables automation of routine tasks, freeing human workers for more creative endeavors. However, concerns about job displacement and ethical implications remain significant. Many experts argue that AI will ultimately create more jobs than it eliminates, though the transition may be challenging.\",\n",
        "            \"Climate change continues to affect ecosystems worldwide at an alarming rate. Rising global temperatures have led to more frequent extreme weather events including hurricanes, floods, and wildfires. Polar ice caps are melting faster than predicted, contributing to sea level rise that threatens coastal communities. Scientists warn that without immediate and dramatic reductions in greenhouse gas emissions, many of these changes may become irreversible. International cooperation remains essential but politically challenging.\",\n",
        "            \"The human genome project was completed in 2003 after 13 years of international collaborative research. It successfully mapped all of the genes of the human genome, approximately 20,000-25,000 genes in total. The project cost nearly $3 billion but has enabled countless medical advances and spawned new fields like pharmacogenomics. The knowledge gained has dramatically improved our understanding of genetic diseases and opened pathways to personalized medicine. Today, a complete human genome can be sequenced in under a day for about $1,000.\",\n",
        "            \"Remote work adoption accelerated dramatically during the COVID-19 pandemic. Organizations that had previously resisted flexible work arrangements were forced to implement digital collaboration tools and virtual workflows. Many companies reported surprising productivity gains, though concerns about company culture and collaboration persisted. After the pandemic, a hybrid model emerged as the preferred approach for many businesses, combining in-office and remote work. This shift has profound implications for urban planning, commercial real estate, and work-life balance.\",\n",
        "            \"Quantum computing represents a fundamental shift in computational capability. Unlike classical computers that use bits as either 0 or 1, quantum computers use quantum bits or qubits that can exist in multiple states simultaneously. This property, known as superposition, theoretically allows quantum computers to solve certain problems exponentially faster than classical computers. Major technology companies and governments are investing billions in quantum research. Fields like cryptography, material science, and drug discovery are expected to be revolutionized once quantum computers reach practical scale.\",\n",
        "        ],\n",
        "        \"targets\": [\n",
        "            \"AI has revolutionized business operations through automation and optimization, though ethical concerns about job displacement persist alongside predictions that AI will ultimately create more employment opportunities than it eliminates.\",\n",
        "            \"Climate change is causing accelerating environmental damage through extreme weather events and melting ice caps, with scientists warning that without immediate reduction in greenhouse gas emissions, many changes may become irreversible.\",\n",
        "            \"The Human Genome Project, completed in 2003, mapped approximately 20,000-25,000 human genes at a cost of $3 billion, enabling medical advances, improving understanding of genetic diseases, and establishing the foundation for personalized medicine.\",\n",
        "            \"The COVID-19 pandemic forced widespread adoption of remote work, revealing unexpected productivity benefits despite collaboration challenges, and resulting in a hybrid work model that impacts urban planning, real estate, and work-life balance.\",\n",
        "            \"Quantum computing uses qubits existing in multiple simultaneous states to potentially solve certain problems exponentially faster than classical computers, with major investment from tech companies and governments anticipating revolutionary applications in cryptography, materials science, and pharmaceutical research.\",\n",
        "        ],\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "429dca7a",
      "metadata": {
        "id": "429dca7a"
      },
      "source": [
        "### 3. Define prediction function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "10a6a4dc",
      "metadata": {
        "id": "10a6a4dc"
      },
      "outputs": [],
      "source": [
        "client = OpenAI()\n",
        "\n",
        "def predict(data: pd.DataFrame) -> list[str]:\n",
        "    predictions = []\n",
        "    prompt = mlflow.load_prompt(\"prompts:/anshu-summarization-prompt/3\")\n",
        "\n",
        "    for _, row in data.iterrows():\n",
        "        # Fill in variables in the prompt template\n",
        "        content = prompt.format(sentences=row[\"inputs\"], num_sentences=1)\n",
        "        completion = client.responses.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            input=[{\"role\": \"user\", \"content\": content}],\n",
        "            temperature=0.1,\n",
        "        )\n",
        "        predictions.append(completion.output_text)\n",
        "\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c272a26d",
      "metadata": {
        "id": "c272a26d"
      },
      "source": [
        "### 4. Run Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "901e013f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9bd7a693f6d14cc2bb83b7a4432fa6ba",
            "398e5032bf4b4bcbbf576521f8ef7180",
            "cce1b5c928714b92a8f2b51e59dca3a1",
            "9c1dea32c113427898bff923658c1a73",
            "22114f89fe8240b2ba0c4c8679a516fe",
            "e7c4441d3a7c4bdd89c022efd9a52942",
            "e9022f70e31740bcbee38fa6f8363217",
            "9a3f86a279334840956cfcddbefa5c97",
            "19e71b621fc047509e9a1ae0ffe6a64f",
            "becb9909058e4afbae74030ea16244f5",
            "d2684a047acb43cfb6bb9b7884c1aec2",
            "bd85046b53c844daa42b985527158d38",
            "809e3dd163a641219248c5d67c93dfc1",
            "3cb9357e9e0a42d8995101045c6142a0",
            "aafd848f1eb44ec2bb6511922658f4a0",
            "279c345cfa9c4e4592c4d23e8071ea1e",
            "96198cc7764d4e0a845452371de53d5e",
            "4668ce32b85d44829c8305a4d9d00bb5",
            "df14cfb91b964ea1ad387232fd29b1b2",
            "263d25c38f1244108594066c9a3479d6",
            "97e6a4a0d0d0408c8d5978124485e41f",
            "db050b1386d946078d2f1af64d8c4e0a"
          ]
        },
        "id": "901e013f",
        "outputId": "174eee6c-8f9f-458f-98b2-f94dfb005274"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/07/18 12:27:32 INFO mlflow.models.evaluation.evaluators.default: Computing model predictions.\n",
            "/tmp/ipython-input-7-3931437831.py:5: FutureWarning: The `mlflow.load_prompt` API is moved to the `mlflow.genai` namespace. Please use `mlflow.genai.load_prompt` instead. The original API will be removed in the future release.\n",
            "  prompt = mlflow.load_prompt(\"prompts:/anshu-summarization-prompt/3\")\n",
            "/tmp/ipython-input-7-3931437831.py:5: FutureWarning: The `mlflow.load_prompt` API is moved to the `mlflow.genai` namespace. Please use `mlflow.genai.load_prompt` instead. The original API will be removed in the future release.\n",
            "  prompt = mlflow.load_prompt(\"prompts:/anshu-summarization-prompt/3\")\n",
            "/tmp/ipython-input-7-3931437831.py:5: FutureWarning: The `mlflow.load_prompt` API is moved to the `mlflow.genai` namespace. Please use `mlflow.genai.load_prompt` instead. The original API will be removed in the future release.\n",
            "  prompt = mlflow.load_prompt(\"prompts:/anshu-summarization-prompt/3\")\n",
            "/tmp/ipython-input-7-3931437831.py:5: FutureWarning: The `mlflow.load_prompt` API is moved to the `mlflow.genai` namespace. Please use `mlflow.genai.load_prompt` instead. The original API will be removed in the future release.\n",
            "  prompt = mlflow.load_prompt(\"prompts:/anshu-summarization-prompt/3\")\n",
            "/tmp/ipython-input-7-3931437831.py:5: FutureWarning: The `mlflow.load_prompt` API is moved to the `mlflow.genai` namespace. Please use `mlflow.genai.load_prompt` instead. The original API will be removed in the future release.\n",
            "  prompt = mlflow.load_prompt(\"prompts:/anshu-summarization-prompt/3\")\n",
            "2025/07/18 12:27:40 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9bd7a693f6d14cc2bb83b7a4432fa6ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/07/18 12:27:42 WARNING mlflow.metrics.metric_definitions: Failed to load 'toxicity' metric (error: ModuleNotFoundError(\"No module named 'evaluate'\")), skipping metric logging.\n",
            "2025/07/18 12:27:42 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'toxicity' at index 1 in the `extra_metrics` parameter because it returned None.\n",
            "2025/07/18 12:27:42 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for flesch kincaid metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n",
            "2025/07/18 12:27:42 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'flesch_kincaid_grade_level' at index 2 in the `extra_metrics` parameter because it returned None.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd85046b53c844daa42b985527158d38"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/07/18 12:27:45 WARNING mlflow.metrics.metric_definitions: Failed to load 'toxicity' metric (error: ModuleNotFoundError(\"No module named 'evaluate'\")), skipping metric logging.\n",
            "2025/07/18 12:27:45 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'toxicity' at index 1 in the `extra_metrics` parameter because it returned None.\n",
            "2025/07/18 12:27:45 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for flesch kincaid metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n",
            "2025/07/18 12:27:45 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'flesch_kincaid_grade_level' at index 2 in the `extra_metrics` parameter because it returned None.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ View run anshu-prompt-evaluation at: http://20.80.248.210:5000/#/experiments/0/runs/dbc4f300bb5a480b81e06b55c5d6c7ef\n",
            "üß™ View experiment at: http://20.80.248.210:5000/#/experiments/0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[Trace(trace_id=25a44e53690642ea8792e92c6a4654cc), Trace(trace_id=30cae5ea401e4be2af6f2d604ceaee08), Trace(trace_id=62dc5c2d9a5541059269e52da5633cde), Trace(trace_id=41aa9279e6694cbeb19a9e8eaf1a65d4), Trace(trace_id=cfef5db190af486ea006116f90869c2e)]"
            ],
            "text/html": [
              "\n",
              "<div>\n",
              "  <style scoped>\n",
              "  button {\n",
              "    border: none;\n",
              "    border-radius: 4px;\n",
              "    background-color: rgb(34, 114, 180);\n",
              "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
              "    font-size: 13px;\n",
              "    color: white;\n",
              "    margin-top: 8px;\n",
              "    margin-bottom: 8px;\n",
              "    padding: 8px 16px;\n",
              "    cursor: pointer;\n",
              "  }\n",
              "  button:hover {\n",
              "    background-color: rgb(66, 153, 224);\n",
              "  }\n",
              "  </style>\n",
              "  <button\n",
              "    onclick=\"\n",
              "        const display = this.nextElementSibling.style.display;\n",
              "        const isCollapsed = display === 'none';\n",
              "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
              "\n",
              "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
              "        this.innerText = `${verb} MLflow Trace`;\n",
              "    \"\n",
              "  >Collapse MLflow Trace</button>\n",
              "  <iframe\n",
              "    id=\"trace-renderer\"\n",
              "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
              "    src=\"http://20.80.248.210:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=25a44e53690642ea8792e92c6a4654cc&amp;experiment_id=0&amp;trace_id=30cae5ea401e4be2af6f2d604ceaee08&amp;experiment_id=0&amp;trace_id=62dc5c2d9a5541059269e52da5633cde&amp;experiment_id=0&amp;trace_id=41aa9279e6694cbeb19a9e8eaf1a65d4&amp;experiment_id=0&amp;trace_id=cfef5db190af486ea006116f90869c2e&amp;experiment_id=0&amp;version=3.1.1\"\n",
              "  />\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "with mlflow.start_run(run_name=\"anshu-prompt-evaluation\"):\n",
        "    mlflow.log_param(\"model\", \"gpt-4o-mini\")\n",
        "    mlflow.log_param(\"temperature\", 0.1)\n",
        "\n",
        "    results = mlflow.evaluate(\n",
        "        model=predict,\n",
        "        data=eval_data,\n",
        "        targets=\"targets\",\n",
        "        extra_metrics=[\n",
        "            mlflow.metrics.latency(),\n",
        "            # Specify GPT4 as a judge model for answer similarity. Other models such as Anthropic,\n",
        "            # Bedrock, Databricks, are also supported.\n",
        "            mlflow.metrics.genai.answer_similarity(model=\"openai:/gpt-4o\"),\n",
        "            mlflow.metrics.toxicity(),\n",
        "            mlflow.metrics.flesch_kincaid_grade_level()\n",
        "        ],\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1391af1b",
      "metadata": {
        "id": "1391af1b"
      },
      "source": [
        "### 5. View Results\n",
        "<img src=\"https://mlflow.org/docs/latest/assets/images/prompt-evaluation-result-7c106f17187fdc750439725d086c389b.png\" alt=\"MLflow LLM Evaluation UI\" width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d3a0cb5",
      "metadata": {
        "id": "7d3a0cb5"
      },
      "source": [
        "<img src = \"https://mlflow.org/docs/latest/assets/images/prompt-evaluation-chart-8a93612e37184b8279c699fd6640013d.png\" >"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6fe7137",
      "metadata": {
        "id": "d6fe7137"
      },
      "source": [
        "## Tracing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.openai.autolog()\n",
        "\n",
        "with mlflow.start_run(run_name=\"anshu123\"):\n",
        "  response = client.responses.create(model='gpt-4o',\n",
        "                                     input='What is quantum computing?')\n",
        "  print(response.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 858
        },
        "id": "0huMSGdsgzYm",
        "outputId": "31bb6b3b-9af0-4f0f-9f3b-6afc8211d068"
      },
      "id": "0huMSGdsgzYm",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantum computing is an advanced field of computing that leverages the principles of quantum mechanics to process information in fundamentally different ways than classical computers. Here are some key aspects:\n",
            "\n",
            "1. **Qubits**: Unlike classical bits, which can be either 0 or 1, qubits can exist in superpositions, where they hold both 0 and 1 simultaneously. This property allows quantum computers to process a vast amount of possibilities at once.\n",
            "\n",
            "2. **Entanglement**: This is a quantum phenomenon where qubits become interconnected such that the state of one qubit can depend on the state of another, no matter how far apart they are. Entanglement enables complex computations that are difficult for classical computers.\n",
            "\n",
            "3. **Quantum Gates**: Quantum computations are conducted using quantum gates, which manipulate qubits through quantum operations. These gates differ significantly from classical logic gates due to their ability to maintain superpositions and entanglements.\n",
            "\n",
            "4. **Quantum Decoherence**: Maintaining the quantum state of qubits is challenging due to decoherence, where unwanted interactions with the environment cause the quantum information to degrade. Researchers work on error-correction methods to counteract this.\n",
            "\n",
            "5. **Applications**: Quantum computing holds promise for solving certain problems much faster than classical computers, such as factoring large numbers, optimizing complex systems, simulating quantum materials, and more.\n",
            "\n",
            "While still in the developmental phase, quantum computing has the potential to revolutionize fields like cryptography, material science, and artificial intelligence.\n",
            "üèÉ View run anshu123 at: http://20.80.248.210:5000/#/experiments/0/runs/d8663568c9f346588b97ce7c750970d2\n",
            "üß™ View experiment at: http://20.80.248.210:5000/#/experiments/0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Trace(trace_id=75fcdf0c7270431e9c04e8135ec3a5fc)"
            ],
            "text/html": [
              "\n",
              "<div>\n",
              "  <style scoped>\n",
              "  button {\n",
              "    border: none;\n",
              "    border-radius: 4px;\n",
              "    background-color: rgb(34, 114, 180);\n",
              "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
              "    font-size: 13px;\n",
              "    color: white;\n",
              "    margin-top: 8px;\n",
              "    margin-bottom: 8px;\n",
              "    padding: 8px 16px;\n",
              "    cursor: pointer;\n",
              "  }\n",
              "  button:hover {\n",
              "    background-color: rgb(66, 153, 224);\n",
              "  }\n",
              "  </style>\n",
              "  <button\n",
              "    onclick=\"\n",
              "        const display = this.nextElementSibling.style.display;\n",
              "        const isCollapsed = display === 'none';\n",
              "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
              "\n",
              "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
              "        this.innerText = `${verb} MLflow Trace`;\n",
              "    \"\n",
              "  >Collapse MLflow Trace</button>\n",
              "  <iframe\n",
              "    id=\"trace-renderer\"\n",
              "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
              "    src=\"http://20.80.248.210:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=75fcdf0c7270431e9c04e8135ec3a5fc&amp;experiment_id=0&amp;version=3.1.1\"\n",
              "  />\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Optimization"
      ],
      "metadata": {
        "id": "2tRzRedvhpZd"
      },
      "id": "2tRzRedvhpZd"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Any\n",
        "import mlflow\n",
        "from mlflow.genai.scorers import scorer\n",
        "from mlflow.genai.optimize import OptimizerConfig, LLMParams"
      ],
      "metadata": {
        "id": "0twXe4Gthxbs"
      },
      "id": "0twXe4Gthxbs",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Register the initial prompt\n",
        "initial_template = \"\"\"\n",
        "Answer to this math question: {{question}}.\n",
        "Return the result in a JSON string in the format of {\"answer\": \"xxx\"}.\n",
        "\"\"\"\n",
        "\n",
        "prompt = mlflow.genai.register_prompt(\n",
        "    name=\"anshu-math\",\n",
        "    template=initial_template,\n",
        ")\n"
      ],
      "metadata": {
        "id": "tiJ1LvQ4h6X2",
        "outputId": "19d27d70-fe71-4322-d14d-c8ae3c6e371a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "tiJ1LvQ4h6X2",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/07/18 12:35:00 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for prompt version to finish creation. Prompt name: anshu-math, version 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# The data can be a list of dictionaries, a pandas DataFrame, or an mlflow.genai.EvaluationDataset\n",
        "# It needs to contain inputs and expectations where each row is a dictionary.\n",
        "train_data = [\n",
        "    {\n",
        "        \"inputs\": {\"question\": \"Given that $y=3$, evaluate $(1+y)^y$.\"},\n",
        "        \"expectations\": {\"answer\": \"64\"},\n",
        "    },\n",
        "    {\n",
        "        \"inputs\": {\n",
        "            \"question\": \"The midpoint of the line segment between $(x,y)$ and $(-9,1)$ is $(3,-5)$. Find $(x,y)$.\"\n",
        "        },\n",
        "        \"expectations\": {\"answer\": \"(15,-11)\"},\n",
        "    },\n",
        "    {\n",
        "        \"inputs\": {\n",
        "            \"question\": \"What is the value of $b$ if $5^b + 5^b + 5^b + 5^b + 5^b = 625^{(b-1)}$? Express your answer as a common fraction.\"\n",
        "        },\n",
        "        \"expectations\": {\"answer\": \"\\\\frac{5}{3}\"},\n",
        "    },\n",
        "    {\n",
        "        \"inputs\": {\"question\": \"Evaluate the expression $a^3\\\\cdot a^2$ if $a= 5$.\"},\n",
        "        \"expectations\": {\"answer\": \"3125\"},\n",
        "    },\n",
        "    {\n",
        "        \"inputs\": {\"question\": \"Evaluate $\\\\lceil 8.8 \\\\rceil+\\\\lceil -8.8 \\\\rceil$.\"},\n",
        "        \"expectations\": {\"answer\": \"17\"},\n",
        "    },\n",
        "]\n",
        "\n",
        "eval_data = [\n",
        "    {\n",
        "        \"inputs\": {\n",
        "            \"question\": \"The sum of 27 consecutive positive integers is $3^7$. What is their median?\"\n",
        "        },\n",
        "        \"expectations\": {\"answer\": \"81\"},\n",
        "    },\n",
        "    {\n",
        "        \"inputs\": {\"question\": \"What is the value of $x$ if $x^2 - 10x + 25 = 0$?\"},\n",
        "        \"expectations\": {\"answer\": \"5\"},\n",
        "    },\n",
        "    {\n",
        "        \"inputs\": {\n",
        "            \"question\": \"If $a\\\\ast b = 2a+5b-ab$, what is the value of $3\\\\ast10$?\"\n",
        "        },\n",
        "        \"expectations\": {\"answer\": \"26\"},\n",
        "    },\n",
        "    {\n",
        "        \"inputs\": {\n",
        "            \"question\": \"Given that $-4$ is a solution to $x^2 + bx -36 = 0$, what is the value of $b$?\"\n",
        "        },\n",
        "        \"expectations\": {\"answer\": \"-5\"},\n",
        "    },\n",
        "]\n"
      ],
      "metadata": {
        "id": "AlkSc7Oth0oU"
      },
      "id": "AlkSc7Oth0oU",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define a custom scorer function to evaluate prompt performance with the @scorer decorator.\n",
        "# The scorer function for optimization can take inputs, outputs, and expectations.\n",
        "@scorer\n",
        "def exact_match(expectations: dict[str, Any], outputs: dict[str, Any]) -> bool:\n",
        "    return expectations[\"answer\"] == outputs[\"answer\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "-DJ_KRZjh_6W"
      },
      "id": "-DJ_KRZjh_6W",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dspy --quiet"
      ],
      "metadata": {
        "id": "rf5s7OD_iRQl",
        "outputId": "28abf7ea-e66d-4ff6-952a-1b245ec45987",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "rf5s7OD_iRQl",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m297.3/297.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m494.8/494.8 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimize the prompt\n",
        "result = mlflow.genai.optimize_prompt(\n",
        "    target_llm_params=LLMParams(model_name=\"openai/gpt-4.1-mini\"),\n",
        "    prompt=prompt,\n",
        "    train_data=train_data,\n",
        "    eval_data=eval_data,\n",
        "    scorers=[exact_match],\n",
        "    optimizer_config=OptimizerConfig(\n",
        "        num_instruction_candidates=8,\n",
        "        max_few_show_examples=2,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# The optimized prompt is automatically registered as a new version\n",
        "print(result.prompt.uri)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "SWCkHV-DhAZX",
        "outputId": "9b5fc860-ef20-493b-8950-5fa2419c459f"
      },
      "id": "SWCkHV-DhAZX",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/07/18 12:37:02 INFO mlflow.genai.optimize.optimizers.dspy_mipro_optimizer: Started optimizing prompt prompts:/anshu-math/1. Please wait as this process typically takes several minutes, but can take longer with large datasets...\n",
            "2025/07/18 12:38:34 INFO mlflow.genai.optimize.optimizers.dspy_mipro_optimizer: Prompt optimization completed. Evaluation score changed from 25.0 to 50.0.\n",
            "/usr/local/lib/python3.11/dist-packages/mlflow/genai/optimize/optimizers/dspy_mipro_optimizer.py:116: FutureWarning: The `mlflow.register_prompt` API is moved to the `mlflow.genai` namespace. Please use `mlflow.genai.register_prompt` instead. The original API will be removed in the future release.\n",
            "  optimized_prompt = register_prompt(\n",
            "2025/07/18 12:38:34 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for prompt version to finish creation. Prompt name: anshu-math, version 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompts:/anshu-math/2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[Trace(trace_id=fbdfecf5480d4e7b8fda34aac435a768), Trace(trace_id=c5aafa1571904e579d69eaa5f56f3a27), Trace(trace_id=93b0cafd3d3c40c9a7f2f9b4d5892306), Trace(trace_id=c274b1f18e03473aa5b99cce516ade15), Trace(trace_id=4ba8528b7b494495bb14d546d2236fe6), Trace(trace_id=1ed09f6938dc479a916bcff35d8f9c10), Trace(trace_id=05418114f595419f9f7659f72aa821c0), Trace(trace_id=e63a73cdd3dd4461b9c393fb7cce45f6), Trace(trace_id=ce6be1386de140d58ec3c72c076367db), Trace(trace_id=3b2211403737488bb7939a8fec40555d)]"
            ],
            "text/html": [
              "\n",
              "<div>\n",
              "  <style scoped>\n",
              "  button {\n",
              "    border: none;\n",
              "    border-radius: 4px;\n",
              "    background-color: rgb(34, 114, 180);\n",
              "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
              "    font-size: 13px;\n",
              "    color: white;\n",
              "    margin-top: 8px;\n",
              "    margin-bottom: 8px;\n",
              "    padding: 8px 16px;\n",
              "    cursor: pointer;\n",
              "  }\n",
              "  button:hover {\n",
              "    background-color: rgb(66, 153, 224);\n",
              "  }\n",
              "  </style>\n",
              "  <button\n",
              "    onclick=\"\n",
              "        const display = this.nextElementSibling.style.display;\n",
              "        const isCollapsed = display === 'none';\n",
              "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
              "\n",
              "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
              "        this.innerText = `${verb} MLflow Trace`;\n",
              "    \"\n",
              "  >Collapse MLflow Trace</button>\n",
              "  <iframe\n",
              "    id=\"trace-renderer\"\n",
              "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
              "    src=\"http://20.80.248.210:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=fbdfecf5480d4e7b8fda34aac435a768&amp;experiment_id=0&amp;trace_id=c5aafa1571904e579d69eaa5f56f3a27&amp;experiment_id=0&amp;trace_id=93b0cafd3d3c40c9a7f2f9b4d5892306&amp;experiment_id=0&amp;trace_id=c274b1f18e03473aa5b99cce516ade15&amp;experiment_id=0&amp;trace_id=4ba8528b7b494495bb14d546d2236fe6&amp;experiment_id=0&amp;trace_id=1ed09f6938dc479a916bcff35d8f9c10&amp;experiment_id=0&amp;trace_id=05418114f595419f9f7659f72aa821c0&amp;experiment_id=0&amp;trace_id=e63a73cdd3dd4461b9c393fb7cce45f6&amp;experiment_id=0&amp;trace_id=ce6be1386de140d58ec3c72c076367db&amp;experiment_id=0&amp;trace_id=3b2211403737488bb7939a8fec40555d&amp;experiment_id=0&amp;version=3.1.1\"\n",
              "  />\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wekHPbjOiPvI"
      },
      "id": "wekHPbjOiPvI",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9bd7a693f6d14cc2bb83b7a4432fa6ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_398e5032bf4b4bcbbf576521f8ef7180",
              "IPY_MODEL_cce1b5c928714b92a8f2b51e59dca3a1",
              "IPY_MODEL_9c1dea32c113427898bff923658c1a73"
            ],
            "layout": "IPY_MODEL_22114f89fe8240b2ba0c4c8679a516fe"
          }
        },
        "398e5032bf4b4bcbbf576521f8ef7180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7c4441d3a7c4bdd89c022efd9a52942",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e9022f70e31740bcbee38fa6f8363217",
            "value": "100%"
          }
        },
        "cce1b5c928714b92a8f2b51e59dca3a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a3f86a279334840956cfcddbefa5c97",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19e71b621fc047509e9a1ae0ffe6a64f",
            "value": 1
          }
        },
        "9c1dea32c113427898bff923658c1a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_becb9909058e4afbae74030ea16244f5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d2684a047acb43cfb6bb9b7884c1aec2",
            "value": "‚Äá1/1‚Äá[00:02&lt;00:00,‚Äá‚Äá2.39s/it]"
          }
        },
        "22114f89fe8240b2ba0c4c8679a516fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7c4441d3a7c4bdd89c022efd9a52942": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9022f70e31740bcbee38fa6f8363217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a3f86a279334840956cfcddbefa5c97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19e71b621fc047509e9a1ae0ffe6a64f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "becb9909058e4afbae74030ea16244f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2684a047acb43cfb6bb9b7884c1aec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd85046b53c844daa42b985527158d38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_809e3dd163a641219248c5d67c93dfc1",
              "IPY_MODEL_3cb9357e9e0a42d8995101045c6142a0",
              "IPY_MODEL_aafd848f1eb44ec2bb6511922658f4a0"
            ],
            "layout": "IPY_MODEL_279c345cfa9c4e4592c4d23e8071ea1e"
          }
        },
        "809e3dd163a641219248c5d67c93dfc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96198cc7764d4e0a845452371de53d5e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4668ce32b85d44829c8305a4d9d00bb5",
            "value": "100%"
          }
        },
        "3cb9357e9e0a42d8995101045c6142a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df14cfb91b964ea1ad387232fd29b1b2",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_263d25c38f1244108594066c9a3479d6",
            "value": 5
          }
        },
        "aafd848f1eb44ec2bb6511922658f4a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97e6a4a0d0d0408c8d5978124485e41f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_db050b1386d946078d2f1af64d8c4e0a",
            "value": "‚Äá5/5‚Äá[00:02&lt;00:00,‚Äá‚Äá2.59it/s]"
          }
        },
        "279c345cfa9c4e4592c4d23e8071ea1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96198cc7764d4e0a845452371de53d5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4668ce32b85d44829c8305a4d9d00bb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df14cfb91b964ea1ad387232fd29b1b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "263d25c38f1244108594066c9a3479d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97e6a4a0d0d0408c8d5978124485e41f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db050b1386d946078d2f1af64d8c4e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}