{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshupandey/prompt_engineering/blob/main/code2_Prompt_Engineering_with_OpenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZBMUH466r3l"
      },
      "source": [
        "# Prompt Engineering Techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Prompt engineering is the process of designing and refining prompts for large language models (LLMs) to elicit desired responses. Different techniques exist to improve the model's performance and controllability."
      ],
      "metadata": {
        "id": "hHVS-OUbexVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = ''"
      ],
      "metadata": {
        "id": "ajIagb_vak5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVEaMctAXC6D"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WAxkVWZ7LRi"
      },
      "outputs": [],
      "source": [
        "# creating a function to get outcome\n",
        "def generate_response(prompt,model=\"gpt-4o\",temperature=0):\n",
        "  messages = [{\"role\":\"user\",\"content\":prompt}]\n",
        "  response = client.responses.create(\n",
        "      model = model,\n",
        "      input = messages,\n",
        "      temperature=temperature\n",
        "  )\n",
        "  return response.output_text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Zero-Shot Prompting\n",
        "**Description:** In zero-shot prompting, the model is given a prompt with a task and no examples of how to perform it. The model is expected to perform the task based solely on its pre-training.\n",
        "\n",
        "**Application Areas:** Simple tasks where the model has a strong understanding from its training data, such as classification, translation, or summarization for common domains.\n",
        "\n",
        "**When to Use:**\n",
        "- When the task is straightforward and aligns well with the model's pre-training.\n",
        "- When collecting examples for few-shot prompting is difficult or time-consuming.\n",
        "- As a baseline to see how well the model performs without explicit examples.\n",
        "\n",
        "**Example:**\n",
        "Prompt: \"Translate the following English sentence to French: 'Hello, how are you?'\"\n",
        "\n"
      ],
      "metadata": {
        "id": "VwRbawJ7fE8C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DpqkFzDvsTe",
        "outputId": "81ae4bbc-e051-464c-b7f4-fea1f83e8109"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Title: The Secret Garden Adventure**\n",
            "\n",
            "**Characters:**\n",
            "- Lily, the curious child\n",
            "- Grandpa Joe, the wise and loving grandparent\n",
            "\n",
            "---\n",
            "\n",
            "**Scene: A sunny afternoon in Grandpa Joe's backyard**\n",
            "\n",
            "**Lily:** Grandpa, can we go on an adventure today?\n",
            "\n",
            "**Grandpa Joe:** An adventure, you say? Well, I think I might have just the thing. Have you ever heard of the secret garden?\n",
            "\n",
            "**Lily:** A secret garden? No, I haven't! Where is it?\n",
            "\n",
            "**Grandpa Joe:** It's right here in our backyard, hidden away from the world. But only those with the keenest eyes and the bravest hearts can find it.\n",
            "\n",
            "**Lily:** Wow! Can we go there now? I want to see it!\n",
            "\n",
            "**Grandpa Joe:** Of course, my little explorer. But first, we need to gather some supplies. Every adventurer needs a trusty backpack. Let's see... a flashlight, a magnifying glass, and some snacks. You never know what we might encounter.\n",
            "\n",
            "**Lily:** I've got my backpack ready, Grandpa! What's next?\n",
            "\n",
            "**Grandpa Joe:** Follow me, Lily. The entrance to the secret garden is through the old wooden gate at the end of the path. But be careful, it's hidden behind the ivy.\n",
            "\n",
            "**Lily:** (giggling) I see it, Grandpa! It's like a door to another world!\n",
            "\n",
            "**Grandpa Joe:** That's the spirit! Now, let's push the gate open and step inside.\n",
            "\n",
            "**(They enter the secret garden, filled with vibrant flowers, towering trees, and the sound of chirping birds.)**\n",
            "\n",
            "**Lily:** It's beautiful, Grandpa! Look at all the colors! And the butterflies!\n",
            "\n",
            "**Grandpa Joe:** This garden has been here for many years, tended by nature itself. It's a place where time seems to stand still, and magic lingers in the air.\n",
            "\n",
            "**Lily:** Do you come here often, Grandpa?\n",
            "\n",
            "**Grandpa Joe:** I do, whenever I need a moment of peace or a reminder of the beauty in the world. It's a special place, just like you, Lily.\n",
            "\n",
            "**Lily:** Can we have our snacks here? I think the butterflies might want to join us.\n",
            "\n",
            "**Grandpa Joe:** That's a wonderful idea. Let's sit by the pond and enjoy our little picnic. And who knows, maybe the garden will share one of its secrets with us today.\n",
            "\n",
            "**(They sit by the pond, sharing snacks and stories, surrounded by the gentle rustle of leaves and the soft hum of nature.)**\n",
            "\n",
            "**Lily:** Thank you for bringing me here, Grandpa. This is the best adventure ever!\n",
            "\n",
            "**Grandpa Joe:** You're welcome, my dear. Remember, the greatest adventures are often found in the simplest of places, as long as you have the right company.\n",
            "\n",
            "**Lily:** I love you, Grandpa.\n",
            "\n",
            "**Grandpa Joe:** I love you too, Lily. Now, let's see if we can spot a frog or two before we head back.\n",
            "\n",
            "**(They continue their exploration, laughter echoing through the secret garden, a memory to cherish forever.)**\n",
            "\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "# zero shot prompting\n",
        "prompt = f\"\"\"\n",
        "Create a conversation story between child and grandparent.\n",
        "\"\"\"\n",
        "response = generate_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Few-Shot Prompting\n",
        "**Description:** Few-shot prompting involves providing the model with a few examples (typically 1 to 5) of the desired input-output pairs before presenting the actual task. This helps the model understand the format and type of output expected.\n",
        "\n",
        "**Application Areas:** Tasks where the desired output format is specific, or the task requires understanding a particular style or pattern. Examples include generating text in a specific style, answering questions in a particular format, or performing tasks on less common data.\n",
        "\n",
        "**When to Use:**\n",
        "- When zero-shot performance is not sufficient.\n",
        "- When the task requires a specific output format or style.\n",
        "- When the task involves domains or data less frequently seen during pre-training.\n",
        "- To guide the model towards desired behavior without fine-tuning.\n",
        "**Example:**\n",
        "Prompt:\n",
        "\"Translate to Spanish:\n",
        "English: 'Goodbye'\n",
        "Spanish: 'Adiós'\n",
        "English: 'Thank you'\n",
        "Spanish: 'Gracias'\n",
        "English: 'Please'\n",
        "Spanish: 'Por favor'\n",
        "English: 'Excuse me'\n",
        "Spanish: 'Disculpe'\"\n"
      ],
      "metadata": {
        "id": "HOgSzz8YfOh1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SurLNqfa6wi",
        "outputId": "d0287807-7b38-4491-bfa5-ec869fe7278a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<grandma>: Resilience is like a tree that bends with the wind but never breaks, standing tall again once the storm has passed.\n"
          ]
        }
      ],
      "source": [
        "# few shot prompting\n",
        "prompt = f\"\"\"\n",
        "your task is to answer in a consistent sytle:\n",
        "\n",
        "<child>: Teach me about patience.\n",
        "<grandma>: Patience is like waiting for whole day to see the moon in the evening and then sleeping after having a look at it.\n",
        "\n",
        "<child>: Teach me about resilience.\n",
        "\"\"\"\n",
        "response = generate_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqtJ2ipJbhw6"
      },
      "source": [
        "#### Few shot prompting with role setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTawSemLbhw6",
        "outputId": "1ca50459-8f74-4008-f3b4-d7c51e17e8de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "positive\n"
          ]
        }
      ],
      "source": [
        "result = client.chat.completions.create(\n",
        "    model='gpt-4o',  # e.g. gpt-35-instant\n",
        "    max_tokens=200,\n",
        "    temperature=0.9,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"That was an awesome experience\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"positive\"},\n",
        "        {\"role\": \"user\", \"content\": \"I won't do that again\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"negative\"},\n",
        "        {\"role\": \"user\", \"content\": \"That was not worth my time\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"negative\"},\n",
        "        {\"role\": \"user\", \"content\": \"You can't miss this\"}\n",
        "    ],\n",
        ")\n",
        "print(result.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Chain-of-Thought (CoT) Prompting\n",
        "**Description:** CoT prompting involves explicitly asking the model to show its reasoning steps or thought process before arriving at the final answer. This is often achieved by including phrases like \"Let's think step by step\" in the prompt. CoT can be used in a zero-shot or few-shot setting (Zero-shot CoT or Few-shot CoT).\n",
        "\n",
        "**Application Areas:** Complex reasoning tasks such as arithmetic, logical deduction, multi-step problem-solving, and question answering that requires synthesis of information.\n",
        "\n",
        "**When to Use:**\n",
        "- When the task requires multi-step reasoning.\n",
        "- When the final answer depends on intermediate steps.\n",
        "- To improve the accuracy on complex problems by guiding the model through the solution process.\n",
        "- To understand the model's reasoning and debug incorrect outputs.\n",
        "**Example (Few-shot CoT):**\n",
        "Prompt:\n",
        "\"Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\n",
        "A: Roger started with 5 balls. He bought 2 cans with 3 balls each, so he bought 2 * 3 = 6 balls. Total balls = 5 + 6 = 11. The answer is 11.\n",
        "\n",
        "Q: The cafeteria had 23 apples. If they used 20 and then bought 6 more, how many apples do they have?\n",
        "A: Let's think step by step. The cafeteria had 23 apples. They used 20, so they had 23 - 20 = 3 apples left. Then they bought 6 more, so they have 3 + 6 = 9 apples. The answer is 9.\n",
        "\n",
        "Q: [New complex question]\n",
        "A: Let's think step by step.\"\n"
      ],
      "metadata": {
        "id": "D5X0lYWVfTeg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbMnOeiq2atC",
        "outputId": "4e46ac4c-279d-4ffe-c716-2c1201a2c8e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To solve this problem, we need to follow the steps:\n",
            "\n",
            "1. Marry initially had 5 pens.\n",
            "2. She gave 3 pens to her friend, so she has \\(5 - 3 = 2\\) pens left.\n",
            "3. She then bought 2 boxes of pens, with 3 pens in each box. This means she bought \\(2 \\times 3 = 6\\) pens.\n",
            "4. Adding the pens she bought to the pens she had left, Marry now has \\(2 + 6 = 8\\) pens.\n",
            "\n",
            "So, Marry has 8 pens now.\n"
          ]
        }
      ],
      "source": [
        "# Without Chain of Thought Prompting\n",
        "prompt = f\"\"\"\n",
        "\n",
        "Teacher: Johan had 5 apples, he bought 4 more boxes with 5 apples each. How many apples does he have now?\n",
        "Student: 25 apples\n",
        "\n",
        "Teacher: Marry had 5 pens, she gave 3 to her friend. and bought 2 boxes of pen with 3 pen in each box. How many pens does she have now?\n",
        "Student:\n",
        "\n",
        "\"\"\"\n",
        "response = generate_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7Hz_cvLbhw_",
        "outputId": "e169ea66-d2f1-4d80-bfe1-e56ae27c27aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Marry initially had 5 pens. She gave 3 pens to her friend, so she had:\n",
            "\n",
            "5 - 3 = 2 pens remaining.\n",
            "\n",
            "Then, she bought 2 boxes with 3 pens in each box, which means she got:\n",
            "\n",
            "2 * 3 = 6 pens.\n",
            "\n",
            "Adding the pens she bought to the pens she had left:\n",
            "\n",
            "2 + 6 = 8 pens.\n",
            "\n",
            "So, Marry has 8 pens now.\n"
          ]
        }
      ],
      "source": [
        "# with Chain of Thought prompting\n",
        "prompt = f\"\"\"\n",
        "\n",
        "Teacher: Johan had 5 apples, he bought 4 more boxes with 5 apples each. How many apples does he have now?\n",
        "Student: Johan had 5 apples, 4 boxes with 5 apples each = 5 + 4*5 = 25 apples\n",
        "\n",
        "Teacher: Marry had 5 pens, she gave 3 to her friend. and bought 2 boxes of pen with 3 pen in each box. How many pens does she have now?\n",
        "Student:\n",
        "\n",
        "\"\"\"\n",
        "response = generate_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7SWadXtr5ou",
        "outputId": "1bd64f0a-dfee-415b-8c53-6ed8c2bbe773"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To solve this problem, let's break it down step by step:\n",
            "\n",
            "1. **Initial Number of Pens:**\n",
            "   - Marry initially had 5 pens.\n",
            "\n",
            "2. **Pens Given Away:**\n",
            "   - She gave 3 pens to her friend.\n",
            "   - So, the number of pens she has after giving away is:  \n",
            "     \\( 5 - 3 = 2 \\) pens.\n",
            "\n",
            "3. **Pens Bought:**\n",
            "   - She bought 2 boxes of pens, with each box containing 3 pens.\n",
            "   - The total number of pens in the boxes is:  \n",
            "     \\( 2 \\times 3 = 6 \\) pens.\n",
            "\n",
            "4. **Total Number of Pens Now:**\n",
            "   - Add the pens she has after giving away to the pens she bought:  \n",
            "     \\( 2 + 6 = 8 \\) pens.\n",
            "\n",
            "Therefore, Marry has 8 pens now.\n"
          ]
        }
      ],
      "source": [
        "# with Chain of Thought prompting\n",
        "prompt = f\"\"\"\n",
        "\n",
        "Think step by step to answer below question, do not come to conclusion without following process.\n",
        "Teacher: Marry had 5 pens, she gave 3 to her friend. and bought 2 boxes of pen with 3 pen in each box. How many pens does she have now?\n",
        "Student:\n",
        "\n",
        "\"\"\"\n",
        "response = generate_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQvoNRxqVo5_"
      },
      "source": [
        "## Tree of Thoughts (ToT)\n",
        "\n",
        "Tree of Thoughts (ToT) prompting is a framework that generalizes over chain-of-thought prompting and encourages exploration over thoughts that serve as intermediate steps for general problem-solving with language models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Description:** ToT is an extension of CoT where the model explores multiple reasoning paths (a tree structure) instead of a single linear chain of thought. It generates multiple intermediate thoughts and explores their consequences, allowing for backtracking and exploration of different possibilities before selecting the most promising path to the solution.\n",
        "\n",
        "**Application Areas:** More complex and open-ended reasoning tasks than CoT, such as creative writing, strategic planning, and problem-solving that might require exploring multiple hypotheses.\n",
        "\n",
        "**When to Use:**\n",
        "- When the problem has multiple potential approaches or intermediate steps.\n",
        "- When a single linear chain of thought might lead to local optima or dead ends.\n",
        "- For tasks requiring more extensive exploration of possibilities.\n",
        "\n",
        "**How it Works (conceptually):** ToT prompting breaks problems down into smaller parts, similar to CoT prompting, but goes further by combining this with the ability to explore multiple solution paths in parallel, forming a tree instead of a single chain. Each thought is generated or solved independently and passed to the next step, allowing the model to self-evaluate and decide whether to continue with that path or choose another.\n",
        "\n",
        "Generate potential intermediate thoughts -> Evaluate their validity/promise -> Select the most promising ones -> Recursively generate further thoughts until a solution is reached. This typically requires more sophisticated prompting or external control mechanisms than basic CoT.\n"
      ],
      "metadata": {
        "id": "X3xmMlSmfXU1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zF7_WBM9MT78",
        "outputId": "efb792e3-b22a-43b6-f533-0a5bad9e0111"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Step 1: Initial Thoughts**\n",
            "\n",
            "**Expert 1:** Carlos likely lost his watch when he shook the towel at the lounger. The vigorous shaking could have dislodged the watch. Probability: 70%\n",
            "\n",
            "**Expert 2:** The watch might have fallen out when Carlos carried the towel to the lounger. The act of carrying it tightly could have caused it to slip out. Probability: 60%\n",
            "\n",
            "**Expert 3:** The watch could be at the snack bar. Carlos left the towel there, and the watch might have fallen out when he put the towel down. Probability: 50%\n",
            "\n",
            "**Expert 4:** It's possible the watch is still in the towel. Carlos might not have noticed it when he left the towel at the snack bar. Probability: 40%\n",
            "\n",
            "**Expert 5:** The watch could have fallen out at any point between the locker room and the diving board. Probability: 30%\n",
            "\n",
            "**Step 2: Critique and Discussion**\n",
            "\n",
            "**Expert 1:** I still believe the shaking at the lounger is the most likely point of loss. However, I acknowledge that the watch could have fallen out earlier.\n",
            "\n",
            "**Expert 2:** I agree with Expert 1 that the shaking is a critical point, but I still think carrying the towel tightly could have dislodged the watch.\n",
            "\n",
            "**Expert 3:** I think the snack bar is a strong possibility because Carlos left the towel there, and it could have fallen out unnoticed.\n",
            "\n",
            "**Expert 4:** I’m reconsidering my position. If the watch was still in the towel, Carlos might have noticed it when he left it at the snack bar.\n",
            "\n",
            "**Expert 5:** I’m leaning towards the watch being lost at a specific point rather than along the way. The shaking at the lounger seems significant.\n",
            "\n",
            "**Step 3: Re-evaluation**\n",
            "\n",
            "**Expert 1:** I’m increasing my probability to 75% for the lounger. The vigorous shaking is a strong indicator.\n",
            "\n",
            "**Expert 2:** I’ll adjust my probability to 65% for the lounger. The shaking seems more likely than carrying.\n",
            "\n",
            "**Expert 3:** I’ll keep my probability at 50% for the snack bar, but I’m open to the lounger being more likely.\n",
            "\n",
            "**Expert 4:** I’m shifting my focus to the lounger. I’ll assign a 60% probability there.\n",
            "\n",
            "**Expert 5:** I’m convinced by the arguments for the lounger. I’ll assign a 70% probability.\n",
            "\n",
            "**Step 4: Conclusion**\n",
            "\n",
            "After considering all possibilities and critiques, the experts agree that the single most likely location of the watch is at the lounger where Carlos vigorously shook the towel. The consensus probability is around 70-75%.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "prompt = \"\"\"\n",
        "Imagine 5 different experts are answering this question.\n",
        "They will brainstorm the answer step by step reasoning carefully and taking all facts into consideration\n",
        "All experts will write down 1 step of their thinking,\n",
        "then share it with the group.\n",
        "They will each critique their response, and the all the responses of others\n",
        "They will check their answer based on science and the laws of physics\n",
        "They will keep going through steps until they reach their conclusion taking into account the thoughts of the other experts\n",
        "If at any time they realise that there is a flaw in their logic they will backtrack to where that flaw occurred\n",
        "If any expert realises they're wrong at any point then they acknowledges this and start another train of thought\n",
        "Each expert will assign a likelihood of their current assertion being correct\n",
        "Continue until the experts agree on the single most likely location\n",
        "The question is.\n",
        "1. Carlos is at the swimming pool.\n",
        "2. He walks to the locker room, carrying a towel.\n",
        "3. He puts his watch in the towel and carries the towel tightly to a lounger at the poolside.\n",
        "4. At the lounger he opens and vigorously shakes the towel, then walks to the snack bar.\n",
        "5. He leaves the towel at the snack bar, then walks to the diving board.\n",
        "6. Later Carlos realises he has has lost his watch. Where is the single most likely location of the watch?\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "ans=generate_response(prompt)\n",
        "\n",
        "print(ans)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ToT Prompt for Loan Application Approval\n",
        "\n",
        "prompt = \"\"\"\n",
        "Imagine 5 different loan officers are reviewing a customer's loan application.\n",
        "They will brainstorm the decision step by step, reasoning carefully and taking all facts into consideration from the application.\n",
        "Each loan officer will write down 1 key observation or analysis step from the application data,\n",
        "then share it with the group.\n",
        "They will each critique their response, and all the responses of others based on standard lending practices and risk assessment criteria.\n",
        "They will check their analysis against established bank policies and economic indicators.\n",
        "They will keep going through steps until they reach their conclusion on whether to approve or reject the loan, taking into account the observations and critiques of the other loan officers.\n",
        "If at any time they realize there is a flaw in their analysis or a crucial piece of information is overlooked, they will backtrack to where that flaw occurred.\n",
        "If any loan officer realizes their assessment is weak or incorrect at any point, they acknowledge this and start another train of thought, focusing on different aspects of the application.\n",
        "Each loan officer will assign a likelihood (e.g., High Risk, Medium Risk, Low Risk) based on their current assertion about the application's overall risk profile.\n",
        "Continue until the loan officers agree on the single most likely outcome (Approve or Reject) based on a consensus risk assessment.\n",
        "\n",
        "The customer's loan application details are as follows:\n",
        "\n",
        "Customer Name: [Customer Name]\n",
        "Loan Amount Requested: [Amount]\n",
        "Loan Type: [e.g., Personal Loan, Mortgage]\n",
        "Annual Income: [Income]\n",
        "Credit Score: [Score]\n",
        "Employment Status: [e.g., Full-time, Self-employed]\n",
        "Employment Duration: [Duration]\n",
        "Existing Debt Obligations: [List or summary]\n",
        "Assets: [List or summary]\n",
        "Purpose of Loan: [Purpose]\n",
        "Payment History: [Summary of past credit behavior]\n",
        "\n",
        "Based on these details, where is the single most likely outcome of the loan application (Approve or Reject)?\n",
        "\"\"\"\n",
        "\n",
        "# Replace bracketed information with actual application details\n",
        "customer_details_prompt = prompt.replace(\"[Customer Name]\", \"John Doe\") \\\n",
        "                               .replace(\"[Amount]\", \"$50,000\") \\\n",
        "                               .replace(\"[Loan Type]\", \"Personal Loan\") \\\n",
        "                               .replace(\"[Income]\", \"$75,000\") \\\n",
        "                               .replace(\"[Score]\", \"720\") \\\n",
        "                               .replace(\"[Employment Status]\", \"Full-time\") \\\n",
        "                               .replace(\"[Employment Duration]\", \"5 years\") \\\n",
        "                               .replace(\"[Existing Debt Obligations]\", \"Credit card balance: $5,000, Auto loan payment: $400/month\") \\\n",
        "                               .replace(\"[Assets]\", \"Savings account: $20,000, Car value: $15,000\") \\\n",
        "                               .replace(\"[Purpose of Loan]\", \"Home renovation\") \\\n",
        "                               .replace(\"[Summary of past credit behavior]\", \"No late payments in the last 3 years\")\n",
        "\n",
        "ans = generate_response(customer_details_prompt)\n",
        "\n",
        "ans\n"
      ],
      "metadata": {
        "id": "ltjr2yv4ixSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ToT Prompt for Enterprise Banking Scenario: Supply Chain Finance Optimization\n",
        "\n",
        "prompt = \"\"\"\n",
        "Imagine 5 different experts in Supply Chain Finance, Risk Management, Data Science, Operations, and Customer Relationship Management are collaborating to address the following challenge:\n",
        "\n",
        "A large manufacturing company, a client of your bank, is experiencing significant working capital strain due to long payment terms with their suppliers (averaging 90 days) and relatively short payment terms from their buyers (averaging 45 days). This creates a cash flow gap that they currently bridge using expensive short-term loans from other institutions.\n",
        "\n",
        "Your bank wants to propose a comprehensive Supply Chain Finance (SCF) solution that benefits both the manufacturing company (the buyer) and their key suppliers, increases the bank's revenue through new products, and strengthens the overall client relationship. The goal is not just to offer a standard factoring or reverse factoring product, but to design an integrated, optimized solution leveraging data and potentially incorporating risk mitigation strategies for the bank.\n",
        "\n",
        "The experts will brainstorm the design of this SCF solution step by step, reasoning carefully and taking all relevant factors into consideration for the buyer, their suppliers, and the bank.\n",
        "\n",
        "All experts will write down 1 step of their thinking related to designing this optimized SCF solution, then share it with the group.\n",
        "They will each critique their response, and all the responses of others.\n",
        "They will consider the perspectives and constraints of the buyer (manufacturing company), their diverse set of suppliers (ranging from large corporations to small businesses), and the bank (risk appetite, operational capacity, revenue goals).\n",
        "They will keep going through steps until they reach a well-defined and compelling SCF solution proposal, taking into account the thoughts of the other experts.\n",
        "If at any time they realize that there is a flaw in their logic or a critical aspect is missed, they will backtrack to where that flaw occurred.\n",
        "If any expert realizes they're wrong at any point, they acknowledge this and start another train of thought.\n",
        "Each expert will assign a likelihood of their current proposed element of the solution being successful or viable.\n",
        "\n",
        "Continue until the experts agree on the single most effective and viable integrated SCF solution proposal that addresses the working capital needs of the buyer and their suppliers while creating a valuable new revenue stream and strengthening the relationship for the bank.\n",
        "\n",
        "The challenge is:\n",
        "Design an optimized and integrated Supply Chain Finance solution for a large manufacturing client facing a working capital gap due to mismatched payment terms, considering the needs of their suppliers and the bank's objectives.\n",
        "\"\"\"\n",
        "\n",
        "ans = generate_response(prompt)\n",
        "ans\n"
      ],
      "metadata": {
        "id": "H2vh3_-Af-gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chain-of-Verification (CoVe) Prompting\n",
        "\n",
        "**Description:** Chain-of-Verification (CoVe) is a prompting technique designed to improve the factual accuracy of Large Language Models (LLMs) by explicitly prompting the model to generate a draft response, then generate verification questions for its own response, answer those questions independently of the initial draft, and finally use the answers to revise and improve the original draft. This creates a self-correction mechanism.\n",
        "\n",
        "**Application Areas:** Tasks requiring high factual accuracy and reduced hallucination, such as question answering, summarization of factual information, and generating reports or summaries based on provided text. It is particularly useful when dealing with complex or potentially ambiguous information where the model might otherwise confidently generate incorrect details.\n",
        "\n",
        "**When to Use:**\n",
        "- When factual accuracy is critical and errors could be harmful or misleading.\n",
        "- To reduce hallucinations and improve the reliability of the model's output.\n",
        "- When verifying information against external sources is not immediately feasible or desired within the prompting process itself.\n",
        "- For generating summaries or answers that require synthesizing information from multiple potential points within the model's knowledge or context.\n",
        "\n",
        "**How it Works:**\n",
        "1. **Generate Initial Draft:** The model first generates a direct answer or response to the original prompt.\n",
        "2. **Generate Verification Questions:** The model is then prompted to generate questions that would help verify the correctness of the statements made in the initial draft.\n",
        "3. **Answer Verification Questions:** The model answers these verification questions *independently* of the initial draft, drawing from its internal knowledge or provided context. This step is crucial as it prevents the model from simply confirming its own potential errors.\n",
        "4. **Revise Initial Draft:** The model compares the answers to the verification questions with the original draft and revises the draft to align with the verified information.\n",
        "\n",
        "This iterative process helps the model identify inconsistencies or inaccuracies in its initial output and correct them before presenting the final response.\n",
        "\n",
        "**Example (Conceptual):**\n",
        "\n",
        "Prompt: \"Explain the process of photosynthesis and its main outputs.\"\n",
        "\n",
        "1.  **Initial Draft (Internal):** \"Photosynthesis is how plants make food. They use sunlight, water, and carbon dioxide. The main output is oxygen and sugar.\" (Might contain slight inaccuracies or missing details).\n",
        "2.  **Generate Verification Questions (Internal):**\n",
        "    *   \"What are the inputs of photosynthesis?\"\n",
        "    *   \"What are the outputs of photosynthesis?\"\n",
        "    *   \"What is the role of chlorophyll?\"\n",
        "    *   \"Where does photosynthesis primarily occur in a plant?\"\n",
        "3.  **Answer Verification Questions (Internal, independently):**\n",
        "    *   \"Inputs are carbon dioxide, water, and light energy.\"\n",
        "    *   \"Outputs are glucose (a sugar) and oxygen.\"\n",
        "    *   \"Chlorophyll is a pigment that absorbs light energy.\"\n",
        "    *   \"It occurs mainly in chloroplasts within plant cells.\"\n",
        "4.  **Revise Initial Draft (Internal, based on verified answers):** \"Photosynthesis is the process by which green plants and some other organisms use sunlight to synthesize foods with the help of chlorophyll. During photosynthesis, plants take in carbon dioxide from the air, water from the soil, and light energy from the sun. Using the energy absorbed by chlorophyll in their chloroplasts, they convert these inputs into glucose, a sugar they use for energy and growth, and oxygen, which is released as a byproduct.\"\n",
        "\n",
        "The final output presented to the user would be the revised draft. While the user doesn't see the intermediate steps, the process happens internally within the model's processing based on the CoVe prompt structure.\n"
      ],
      "metadata": {
        "id": "jEUSbUTejH1L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9mjZtAJfDdm",
        "outputId": "22e66ffd-5e73-478c-a44b-f6e168cbd015"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial Response:\n",
            "Some athletes who were born in the United States include Michael Jordan, Serena Williams, Tom Brady, Simone Biles, and LeBron James.\n",
            "\n",
            "Verification Questions and Answers:\n",
            "\n",
            "1. Was Michael Jordan born in the United States?\n",
            "   - Yes, Michael Jordan was born in Brooklyn, New York, United States.\n",
            "\n",
            "2. Was Serena Williams born in the United States?\n",
            "   - Yes, Serena Williams was born in Saginaw, Michigan, United States.\n",
            "\n",
            "3. Was Tom Brady born in the United States?\n",
            "   - Yes, Tom Brady was born in San Mateo, California, United States.\n",
            "\n",
            "4. Was Simone Biles born in the United States?\n",
            "   - Yes, Simone Biles was born in Columbus, Ohio, United States.\n",
            "\n",
            "5. Was LeBron James born in the United States?\n",
            "   - Yes, LeBron James was born in Akron, Ohio, United States.\n",
            "\n",
            "Revised Final Response:\n",
            "After verifying the information, it is confirmed that all the athletes mentioned were indeed born in the United States. Therefore, some athletes who were born in the United States include Michael Jordan, Serena Williams, Tom Brady, Simone Biles, and LeBron James.\n"
          ]
        }
      ],
      "source": [
        "Question=\"Name some athletes who were born in United states\"\n",
        "\n",
        "prompt=f'''Here is the question: {Question}.\n",
        "\n",
        "First, generate a response.\n",
        "\n",
        "Then, create and answer verification questions based on this response to check for accuracy. Think it through and make sure you are extremely accurate based on the question asked.\n",
        "\n",
        "After answering each verification question, consider these answers and revise the initial response to formulate a final, verified answer. Ensure the final response reflects the accuracy and findings from the verification process.'''\n",
        "\n",
        "\n",
        "\n",
        "ans=generate_response(prompt)\n",
        "\n",
        "print(ans)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "In an enterprise banking context, a customer is requesting a complex derivative trade. This involves intricate details regarding the underlying asset, notional value, tenor, strike price, option type (if applicable), counterparty credit risk, regulatory compliance, and internal risk limits.\n",
        "\n",
        "The task is to assess the viability and risks of this specific derivative trade request for the bank.\n",
        "\n",
        "First, generate an initial assessment of the trade request, including potential benefits and immediate red flags based on standard derivative trading practices and market knowledge.\n",
        "\n",
        "Then, create and answer a series of verification questions specifically tailored to validate the critical details and associated risks mentioned in the initial assessment. Think through each question carefully, drawing upon knowledge of financial instruments, risk management frameworks, regulatory requirements (e.g., Dodd-Frank, EMIR), and internal banking policies.\n",
        "\n",
        "Examples of potential verification questions:\n",
        "- Is the counterparty's credit risk within acceptable limits for a trade of this size and tenor?\n",
        "- Does this trade comply with all relevant regulatory requirements for derivative transactions?\n",
        "- Does the pricing of this derivative accurately reflect current market conditions and volatility?\n",
        "- How does this trade impact the bank's overall exposure to the underlying asset?\n",
        "- Are the operational processes and systems in place to handle the settlement and ongoing management of this specific derivative type?\n",
        "- Has the client undergone the necessary suitability and appropriateness checks for complex products like this?\n",
        "\n",
        "After answering each verification question independently, consider these answers and revise the initial assessment to formulate a final, verified decision on whether to proceed with the trade, including any necessary conditions or risk mitigation steps. Ensure the final response is a comprehensive analysis reflecting the accuracy and findings from the verification process and aligns with the bank's risk appetite and policies.\n",
        "\n",
        "The customer's derivative trade request details are:\n",
        "[Provide specific details of the trade request here, e.g.,\n",
        "Underlying Asset: EUR/USD currency pair\n",
        "Notional Value: $100,000,000\n",
        "Tenor: 2 years\n",
        "Trade Type: FX Forward\n",
        "Client: [Client Name], Credit Rating: [Rating]\n",
        "Purpose: Hedging foreign exchange exposure]\n",
        "\"\"\"\n",
        "\n",
        "# Replace bracketed information with actual trade request details\n",
        "trade_details_prompt = prompt.replace(\"[Provide specific details of the trade request here...]\",\n",
        "                                       \"\"\"Underlying Asset: Interest Rate Swap (Fixed-to-Floating USD)\n",
        "Notional Value: $250,000,000\n",
        "Tenor: 5 years\n",
        "Trade Type: Receive Fixed, Pay Floating\n",
        "Client: [Client Name], Credit Rating: AA-\n",
        "Purpose: Hedge against rising interest rates on existing floating-rate debt\"\"\")\n",
        "\n",
        "ans = generate_response(trade_details_prompt)\n",
        "ans\n"
      ],
      "metadata": {
        "id": "z-AcZ3o3jinD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ReAct Prompting\n",
        "**Description:** ReAct (Reasoning and Acting) prompting is a technique that combines reasoning trace generation with task-specific actions. It encourages the model to interleave thinking steps (Reasoning) with taking actions (Acting) through tools or interacting with an environment. The model observes the outcomes of its actions and uses this information to refine its subsequent reasoning and actions. This allows the model to perform tasks that require interacting with external sources of information or performing physical (or simulated physical) actions.\n",
        "\n",
        "**Application Areas:** Tasks that require external knowledge lookup, interacting with APIs or tools, complex decision-making, and environments where actions have observable consequences. Examples include answering questions that require searching the web, using a calculator for complex math, interacting with a simulated game environment, or completing tasks that involve multiple external steps.\n",
        "\n",
        "**When to Use:**\n",
        "- When the task requires up-to-date information not present in the model's training data.\n",
        "- When the task involves complex calculations or operations that the model is not inherently good at performing reliably.\n",
        "- When the task requires interacting with external systems or data sources.\n",
        "- To enable the model to break down a complex task into smaller, executable steps based on external feedback.\n",
        "\n",
        "**How it Works (Simulated in a Prompt):** In a prompt, ReAct is simulated by guiding the model to explicitly state its \"Thought\" process (reasoning about the next step or action) and its \"Action\" (the action it would take or the tool it would use), followed by an \"Observation\" (the simulated result of the action). The model then uses the Observation to inform its next Thought and Action.\n"
      ],
      "metadata": {
        "id": "YHcwBHMjkb5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "You are a helpful assistant that can answer questions by first thinking step-by-step about the question, then deciding on an action (like searching or using a tool), observing the result of the action, and then repeating the process until you can formulate a final answer.\n",
        "\n",
        "Your process should follow this format:\n",
        "\n",
        "Thought: Think step-by-step about the question and what information you need to answer it.\n",
        "Action: [Describe the action you would take or tool you would use]\n",
        "Observation: [Simulate the result of the action]\n",
        "... (Repeat Thought, Action, Observation until you have enough information)\n",
        "Thought: Now that I have the necessary information, I can formulate the final answer.\n",
        "Final Answer: [Provide the final answer]\n",
        "\n",
        "Here is the question: What is the current population of Tokyo?\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "ans = generate_response(prompt)\n",
        "print(ans)\n"
      ],
      "metadata": {
        "id": "jak5rQ_ekwj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt = \"\"\"\n",
        "You are an expert financial analyst assistant. You need to determine if a company's stock is overvalued based on its current P/E ratio compared to the industry average.\n",
        "\n",
        "Follow the ReAct process:\n",
        "\n",
        "Thought: Think step-by-step about how to assess if the stock is overvalued based on the P/E ratio.\n",
        "Action: [Describe the action to find the company's current stock price and EPS to calculate its P/E ratio]\n",
        "Observation: [Simulate the result, e.g., \"Company X Stock Price: $150, EPS: $5.00\"]\n",
        "Thought: Calculate the company's P/E ratio.\n",
        "Action: [Describe the calculation: Stock Price / EPS]\n",
        "Observation: [Simulate the result, e.g., \"Company X P/E Ratio: 30x\"]\n",
        "Thought: Find the industry average P/E ratio for comparison.\n",
        "Action: [Describe the action to find the industry average P/E ratio for the relevant sector (e.g., Technology)]\n",
        "Observation: [Simulate the result, e.g., \"Industry Average P/E Ratio (Technology): 25x\"]\n",
        "Thought: Compare the company's P/E ratio to the industry average and determine if it is overvalued.\n",
        "Action: [Describe the comparison and decision process]\n",
        "Observation: [Simulate the result of the comparison]\n",
        "Thought: Formulate the final assessment.\n",
        "Final Answer: [Provide the final assessment based on the P/E comparison]\n",
        "\n",
        "Here is the company: Company X (Technology Sector)\n",
        "\"\"\"\n",
        "\n",
        "ans = generate_response(prompt)\n",
        "print(ans)"
      ],
      "metadata": {
        "id": "xr_yEd3Wjw6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-DmK07y94x8"
      },
      "source": [
        "## Conversational App"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lap6MZ-ARdKd"
      },
      "outputs": [],
      "source": [
        "# creating a function to get outcome\n",
        "def generate_response(messages,model='gpt-4o'):\n",
        "  response = client.chat.completions.create(\n",
        "      model = model,\n",
        "      messages = messages,\n",
        "      temperature=0.5\n",
        "  )\n",
        "  return response.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgHXbLb0bhxA",
        "outputId": "1dddbf0c-edcd-4ee2-e6cc-77398101967b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You:  Hi My name is ANshu, I live in Mumbai. \n",
            "Bot: Hello Anshu! It's nice to meet you. How can I assist you today?\n",
            "You:  tell me about the city I live in .\n",
            "Bot: Certainly! Mumbai, formerly known as Bombay, is the capital city of the Indian state of Maharashtra. It's the most populous city in India and one of the most densely populated cities in the world. Here are some key points about Mumbai:\n",
            "\n",
            "1. **Economic Hub**: Mumbai is the financial, commercial, and entertainment capital of India. It is home to major financial institutions like the Reserve Bank of India, the Bombay Stock Exchange, and numerous multinational corporations. The city contributes significantly to India's GDP.\n",
            "\n",
            "2. **Bollywood**: Mumbai is synonymous with Bollywood, the Hindi-language film industry. It produces a large number of films each year and is a major cultural influence in India and beyond.\n",
            "\n",
            "3. **Cultural Diversity**: The city is a melting pot of cultures, with a diverse population that includes people from all over India and the world. This diversity is reflected in its cuisine, festivals, and languages.\n",
            "\n",
            "4. **Landmarks and Attractions**: Mumbai has several iconic landmarks, such as the Gateway of India, Marine Drive, Chhatrapati Shivaji Maharaj Terminus (a UNESCO World Heritage Site), and the Elephanta Caves. The city also boasts beautiful beaches like Juhu and Chowpatty.\n",
            "\n",
            "5. **Education and Institutions**: Mumbai is home to some of India's premier educational and research institutions, including the University of Mumbai, the Indian Institute of Technology Bombay (IIT Bombay), and the Tata Institute of Social Sciences (TISS).\n",
            "\n",
            "6. **Public Transport**: The city's public transport system is extensive, with suburban railways, buses, and a growing metro network. The Mumbai local trains are a lifeline for millions of commuters.\n",
            "\n",
            "7. **Challenges**: Like any major metropolis, Mumbai faces challenges such as traffic congestion, pollution, and housing shortages. The city is also vulnerable to monsoon flooding.\n",
            "\n",
            "8. **Vibrant Nightlife and Cuisine**: Mumbai offers a vibrant nightlife with numerous bars, clubs, and restaurants. The city is famous for its street food, including vada pav, pav bhaji, and bhel puri.\n",
            "\n",
            "Overall, Mumbai is a dynamic city with a rich history and a promising future, known for its resilience and spirit. If there's anything specific you'd like to know, feel free to ask!\n",
            "You:  exit\n"
          ]
        }
      ],
      "source": [
        "messages = [{\"role\":\"system\",\"content\":\"You are a helpful assistant\"},]\n",
        "while True:\n",
        "    uinput = input(\"You: \")\n",
        "    print(\"You: \",uinput)\n",
        "    if uinput.lower() in ['q','quit','exit']:\n",
        "        break\n",
        "    messages.append({\"role\":\"user\",\"content\":uinput})\n",
        "    response = generate_response(messages=messages)\n",
        "    print(f\"Bot: {response}\")\n",
        "    messages.append({\"role\":\"assistant\",\"content\":response})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CkR8go1aWeW",
        "outputId": "27d08f33-8c6d-4f2f-99bb-5ad62bb85052"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'role': 'system', 'content': 'You are a helpful assistant'},\n",
              " {'role': 'user', 'content': 'Hi My name is ANshu, I live in Mumbai. '},\n",
              " {'role': 'assistant',\n",
              "  'content': \"Hello Anshu! It's nice to meet you. How can I assist you today?\"},\n",
              " {'role': 'user', 'content': 'tell me about the city I live in .'},\n",
              " {'role': 'assistant',\n",
              "  'content': \"Certainly! Mumbai, formerly known as Bombay, is the capital city of the Indian state of Maharashtra. It's the most populous city in India and one of the most densely populated cities in the world. Here are some key points about Mumbai:\\n\\n1. **Economic Hub**: Mumbai is the financial, commercial, and entertainment capital of India. It is home to major financial institutions like the Reserve Bank of India, the Bombay Stock Exchange, and numerous multinational corporations. The city contributes significantly to India's GDP.\\n\\n2. **Bollywood**: Mumbai is synonymous with Bollywood, the Hindi-language film industry. It produces a large number of films each year and is a major cultural influence in India and beyond.\\n\\n3. **Cultural Diversity**: The city is a melting pot of cultures, with a diverse population that includes people from all over India and the world. This diversity is reflected in its cuisine, festivals, and languages.\\n\\n4. **Landmarks and Attractions**: Mumbai has several iconic landmarks, such as the Gateway of India, Marine Drive, Chhatrapati Shivaji Maharaj Terminus (a UNESCO World Heritage Site), and the Elephanta Caves. The city also boasts beautiful beaches like Juhu and Chowpatty.\\n\\n5. **Education and Institutions**: Mumbai is home to some of India's premier educational and research institutions, including the University of Mumbai, the Indian Institute of Technology Bombay (IIT Bombay), and the Tata Institute of Social Sciences (TISS).\\n\\n6. **Public Transport**: The city's public transport system is extensive, with suburban railways, buses, and a growing metro network. The Mumbai local trains are a lifeline for millions of commuters.\\n\\n7. **Challenges**: Like any major metropolis, Mumbai faces challenges such as traffic congestion, pollution, and housing shortages. The city is also vulnerable to monsoon flooding.\\n\\n8. **Vibrant Nightlife and Cuisine**: Mumbai offers a vibrant nightlife with numerous bars, clubs, and restaurants. The city is famous for its street food, including vada pav, pav bhaji, and bhel puri.\\n\\nOverall, Mumbai is a dynamic city with a rich history and a promising future, known for its resilience and spirit. If there's anything specific you'd like to know, feel free to ask!\"}]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLeNuP-yaWeX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WErsqIf94x9"
      },
      "source": [
        "## Thank You"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoaLQdSYaWeY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksqyGiZbaWeZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}